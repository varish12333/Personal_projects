{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33908a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9776733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10734fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\66738\\\\OneDrive - Bain\\\\Documents\\\\Personal Docs\\\\Agents - AI\\\\RAG_\\\\Personal_projects'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc8da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 PDF files to process\n",
      "\n",
      "Processing: sample.pdf\n",
      "  ✓ Loaded 2 pages\n",
      "\n",
      "Total documents loaded: 2\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89531867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content='WORK EXPERIENCE \\n \\nSr. Data Scientist | SymphonyAI | Dec’ 23-Ongoing \\n \\n➢  AI for Work : Developed Agentic AI Studio, a low -code/no-code, easily \\ncustomizable SaaS product aimed at improving employee productivity . The \\nplatform allows users to define a flow by dragging components onto a canvas, \\nseamlessly connecting them to agents to trigger their agentic flow.  \\n \\n•  Built custom components /MCP servers  for HR, IT, coding assistance and \\nemployees general queries, which are available as out-of-the-box templates for \\nnew customers. Utilized Langflow, Langchain and Langfuse for development. \\n \\n➢  Enterprise Knowledge Management (EKM):  Developed a RAG -based \\napplication that integrates with SharePoint and Confluence to retrieve \\npersonalized knowledge articles based on user location, role, and permission, \\ndelivering precise response tailored to each user’s needs. \\n \\n•  Used advance d techniques like re -ranking, multi -query, parent document \\nretriever, follow-up questions and fine-tuned embedding model (used MRL). \\n \\n➢  Copilot:  Developed a copilot to automate 70% of ITSM tasks for analysts \\nand end users, from creating service requests to resolving tickets. It also \\nhandles scheduling meetings, booking flights, applying for leave,  checking \\ncompany policies and many more , making it an all -in-one platform for various \\ntasks. Used LangGraph for development and deployed on AKS. \\n \\n➢  Service Desk Intelligence (SDI):  Trained a Tensorflow based non-linear \\nNN model using diverse data types to predict ticket escalation risk, change \\nmanagement success probability and resolution SLA meet probability.  \\n \\n•  Developed a Catch-And-Dispatch optimization model to assign new tickets to \\nthe best-suited workgroup and analyst . Implemented MILP using pulp library, \\nresulting in a measurable reduction in resolution time and improved analyst \\nefficiency. \\n➢  MLOps and ETL pipeline:  Automated data science life cycle by using \\nAzure Data Factory, Databricks/PySpark and Azure ML  to trigger model training \\non new data, perform hypermeter tuning, register the best model and deploy \\nit to production while maintaining version control. \\n \\nData Scientist | Koch Business Solutions | May’ 21-Dec’ 23 \\n \\n➢  Nqaire : Designed a LLM based chatbot utilizing Azure OpenAI and \\nLangchain, to analyse global events\\' financial, economic, and other impacts on \\nKoch companies by amalgamating external internet data with internal data . \\n \\n•  The chatbot exhibits memory, possesses the ability to query internal DB  - by \\ngenerating SQL queries, search Wikipedia/Google News, formulate probing \\nquestions to enhance analysis,  suggest better prompts  and can present output \\nin the form of charts, tables, or summarized text, detailing impacts. \\n \\n➢ Cell/CTB Forecast : Conducted mill -level production volume forecas t for \\nproduct - Cellulose and Containerboard to enhance inventory management, \\nproduction optimization, and customer satisfaction. \\n \\n•  Employed SARIMAX  on four years of monthly training data to forecast 12 \\nmonths ahead. Integrated planned outages and business forecast  as \\nexogenous variables in the models. \\n \\n➢  Sheet Feeders Pricing : Led a pricing strategy initiative to enhance and \\nstandardize pricing for Sheet Feeders products by leveraging historical \\ntransaction data to improve profitability. \\n \\n•  Proposed model focused on adjusting \"Ma terial Margin as % of Net Sales \\n(MMP)\" to enforce a 20% profitability floor by shifting low -margin transactions \\nbelow the MMP median. \\n \\n \\n \\n \\n \\n \\n     ADITYA  GAURAV  \\n \\uf028 +91-7845820047 \\n \\uf02a  advit200@gmail.com  \\n   Github.com/Advit200 \\n \\n   linkedin.com/in/advit200 \\n \\nExperienced Data Scientist with close to 9 years of \\nexpertise in  data analysis, ML/DL/Gen AI  and \\ntransforming business objectives into actionable data \\nscience tasks and generating value through AI. \\nDemonstrates strong analytical and problem -solving \\ncapabilities, meticulous attention to detail, and \\nexcellent teamwork skills. \\n \\nP R O F I L E  S Y N P O S I S \\n \\n▪ Adept at creating Enterprise grade Agentic LLM based \\napplication, fine tuning LLM/embedding model & RAG. \\n \\n▪ Proficient in developing , enhancing and maintaining \\nTime Series, Supervised Machine Learning and Deep \\nLearning based Predictive and Statistical models. \\n \\n \\n▪ Experienced in MLOps, managing the complete AI \\nlifecycle from ETL pipeline development to model \\ndeployment on cloud platforms – AWS and Azure. \\n \\n \\n▪ Possesses a solid grasp of Statistics, Hypothesis Testing \\nand Mathematics behind AI algorithms. \\n \\n \\n▪ Proficient in writing optimized Python code with a \\nstrong understanding of DSA and OOPs concepts. \\n \\n▪ Good knowledge of AWS and Azure cloud services, \\nincluding Azure ML Studio, Azure Data Factory, Azure \\nApp services and Azure Kubernetes Service. \\n \\n▪ Basic knowledge of Big Data ecosystem and Pyspark. \\n \\nT E C H N I C A L  S K I L L S \\nLanguages Python, SAS, SQL \\n \\nML Domain Regression, Classification, NLP, \\nClustering, Pricing, Time Series, \\nNetwork Analysis, Gen AI/LLM \\n \\nDatabases MySQL, MongoDB, Vector DB \\n \\n \\nWeb Framework Flask, Django, FastAPI \\n \\nBI Tool Power BI, Tableau \\n \\n \\nCloud AWS, Azure \\n \\nC E R T I F I C A T I O N \\n▪ Microsoft certified - Azure Fundamentals   \\n \\n \\n▪ Applied Accelerated AI – NPTEL (Nvidia) \\n \\n \\n▪ Data Structure & Algorithm,Python– NPTEL(IIT Madras) \\n \\n \\n▪ Network Analysis and Network Optimization – SAS \\n \\n▪ Generative AI with Large Language Model - Coursera \\n \\n \\nE D U C A T IO N \\nCollege Degree CGPA Year \\nBITS Pilani MTech-AIML \\n \\n8.49 2023-25 \\nVIT University, Vellore \\n \\nBTech-Mech \\n \\n8.55 2012-16 \\nDAV Public School \\n \\nClass-XII \\n \\n78% 2011 \\nDAV Public School Class-X 83% 2009'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content=\"➢  BitterSweet: The project's objective was to construct an aggregator featuring integrated text analytics and insights for Koch Industries \\nby collecting and analysing reviews from diverse social media platforms . \\n \\n•  Conducted Sentiment Analysis, Aspect -based sentiment analysis  employing a NLI model and Topic Modelling  on the review text . The \\nresulting analysis provided valuable insights for organizational leaders to evaluate the company's reputation and identify potential issues \\nwithin their respective units. \\n \\n➢  Voice of customer : VOC project was aimed at identifying patterns in data and performing text analytics on customer’s feedback  to \\nfind key factors influencing customer experience during different stages of business and suggest possible areas of improvement. \\n \\n•  Employed diverse NLP techniques, including keyword extraction  (KeyBERT), NER (Spacy), Topic modelling  (BERTopic). Analysis of \\nnegative feedback revealed that delayed equipment delivery, fabrication issues, and response time were prominent factors cont ributing \\nto customer dissatisfaction. \\n \\n➢  Tissue Softness Prediction: Project's goal was to create a real-time alert system for operators, facilitating prompt quality checks and \\nminimizing waste due to tissue softness degradation. Developed a predictive model using streaming sensor data to predict tissue \\nsoftness at 10-minute intervals. \\n \\n•  Applied Genetic Algorithm for feature selection and built a unified XGBoost model across 10 plants . Deployed the model on SAS ESP . \\nUtilized SHAPLEY values for cause-effect analysis, aiding plant operators in decision-making. \\n \\nSr. Data Analyst | Accenture | Jan’ 17 – April’21 \\n \\n➢ OneReport : This project centers on the development of a web application for data owners to upload data files, with automatic data  \\nretrieval from the database, leading to the creation of a consolidated Data Lake that facilitates effortless Power BI refreshing. \\n \\n• Engineered the web application's backend using Django with MongoDB as the database, streamlining the data preprocessing pipel ine.  \\nImplemented features for data validation, checks, and PII or sensitive information encryption before database insertion. \\n \\n• Enabled Row-Level Security (RLS) and Scheduled Refresh for Power BI using Data Gateway. Additionally, developed a monthly email and   \\nTeams notification system through Flask API. \\n \\n➢  AQI Tool : The project's primary goal was to develop a tool for the comparative analysis of business documents (Excel, CSV, PDF, PPT) \\nagainst a standardized template, based on 14 metrics, ultimately generating an Asset Quality Index (AQI) . \\n \\n• Designed a graphical user interface  (GUI) using tkinter, enabling users to select multiple files, apply filters/search functionality, and \\ngenerate detailed reports along with the AQI . Implemented OCR for extracting text from images and employed TF -IDF with cosine \\nsimilarity to identify duplicate images, sections, and tables within the documents . \\n \\n \\n                                                                                 \\n \\nPERSONAL PROJECTS \\n \\n• Developed a sentiment classification model, which involved training a custom BERT model with PyTorch. API deployment was managed \\nthrough Nginx, Docker, and Kubernetes on AWS-EKS. \\n \\n• Constructed a supervised machine translation model utilizing the Locality -Sensitive Hashing (LSH)  based k-Nearest Neighbours (k-NN) \\ntechnique to translate English words into French. \\n \\n• Created a chess game between human-computer using the Minimax and Alpha-Beta Pruning algorithms for strategic move selection. \\n \\n• Developed a rabbit maze game employing A* and Hill climbing algorithm to navigate the maze efficiently and escape with minimal cost. \\n \\nACHIEVEMENTS \\n• Worked as Python & Data Analytics Instructor/Mentor for a batch of 10 freshers at KTC. \\n \\n• Received Spot Bonus 5 times in two years at KTC. \\n \\n \\n• Gold Badge in Python and SQL – HackerRank. \\n \\n• Secured GATE score (Mechanical) of 647 (95 percentile).\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f32c3f",
   "metadata": {},
   "source": [
    "'''chunk_size means “the maximum allowed size of a chunk, measured by whatever your length_function counts.”\n",
    "\n",
    "If length_function = len → count characters → chunk_size=500 = 500 characters.\n",
    "\n",
    "If length_function = tokenizer → count tokens → chunk_size=500 = 500 tokens.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89435ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Suppose you have a 4,000-character PDF page.\\nWith chunk_size=1000 and chunk_overlap=200:\\n\\nChunk 1: characters 0–1000\\n\\nChunk 2: characters 800–1800\\n\\nChunk 3: characters 1600–2600\\n\\nChunk 4: characters 2400–3400\\n\\nChunk 5: characters 3200–4000\\n\\n✅ Overlap ensures continuity. If a sentence starts at the end of one chunk, it won’t get lost'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Suppose you have a 4,000-character PDF page.\n",
    "With chunk_size=1000 and chunk_overlap=200:\n",
    "\n",
    "Chunk 1: characters 0–1000\n",
    "\n",
    "Chunk 2: characters 800–1800\n",
    "\n",
    "Chunk 3: characters 1600–2600\n",
    "\n",
    "Chunk 4: characters 2400–3400\n",
    "\n",
    "Chunk 5: characters 3200–4000\n",
    "\n",
    "✅ Overlap ensures continuity. If a sentence starts at the end of one chunk, it won’t get lost'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e427ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance.\n",
    "    \n",
    "    Splitting priority:\n",
    "    1. Double newlines (\\n\\n) → paragraphs\n",
    "    2. Single newlines (\\n) → sentences/line breaks\n",
    "    3. Spaces (\" \") → words\n",
    "    4. Characters (\"\") → fallback\n",
    "    \"\"\"\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593cb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2 documents into 12 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: WORK EXPERIENCE \n",
      " \n",
      "Sr. Data Scientist | SymphonyAI | Dec’ 23-Ongoing \n",
      " \n",
      "➢  AI for Work : Developed Agentic AI Studio, a low -code/no-code, easily \n",
      "customizable SaaS product aimed at improving employee...\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content='WORK EXPERIENCE \\n \\nSr. Data Scientist | SymphonyAI | Dec’ 23-Ongoing \\n \\n➢  AI for Work : Developed Agentic AI Studio, a low -code/no-code, easily \\ncustomizable SaaS product aimed at improving employee productivity . The \\nplatform allows users to define a flow by dragging components onto a canvas, \\nseamlessly connecting them to agents to trigger their agentic flow.  \\n \\n•  Built custom components /MCP servers  for HR, IT, coding assistance and \\nemployees general queries, which are available as out-of-the-box templates for \\nnew customers. Utilized Langflow, Langchain and Langfuse for development. \\n \\n➢  Enterprise Knowledge Management (EKM):  Developed a RAG -based \\napplication that integrates with SharePoint and Confluence to retrieve \\npersonalized knowledge articles based on user location, role, and permission, \\ndelivering precise response tailored to each user’s needs. \\n \\n•  Used advance d techniques like re -ranking, multi -query, parent document'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content='delivering precise response tailored to each user’s needs. \\n \\n•  Used advance d techniques like re -ranking, multi -query, parent document \\nretriever, follow-up questions and fine-tuned embedding model (used MRL). \\n \\n➢  Copilot:  Developed a copilot to automate 70% of ITSM tasks for analysts \\nand end users, from creating service requests to resolving tickets. It also \\nhandles scheduling meetings, booking flights, applying for leave,  checking \\ncompany policies and many more , making it an all -in-one platform for various \\ntasks. Used LangGraph for development and deployed on AKS. \\n \\n➢  Service Desk Intelligence (SDI):  Trained a Tensorflow based non-linear \\nNN model using diverse data types to predict ticket escalation risk, change \\nmanagement success probability and resolution SLA meet probability.  \\n \\n•  Developed a Catch-And-Dispatch optimization model to assign new tickets to \\nthe best-suited workgroup and analyst . Implemented MILP using pulp library,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content=\"•  Developed a Catch-And-Dispatch optimization model to assign new tickets to \\nthe best-suited workgroup and analyst . Implemented MILP using pulp library, \\nresulting in a measurable reduction in resolution time and improved analyst \\nefficiency. \\n➢  MLOps and ETL pipeline:  Automated data science life cycle by using \\nAzure Data Factory, Databricks/PySpark and Azure ML  to trigger model training \\non new data, perform hypermeter tuning, register the best model and deploy \\nit to production while maintaining version control. \\n \\nData Scientist | Koch Business Solutions | May’ 21-Dec’ 23 \\n \\n➢  Nqaire : Designed a LLM based chatbot utilizing Azure OpenAI and \\nLangchain, to analyse global events' financial, economic, and other impacts on \\nKoch companies by amalgamating external internet data with internal data . \\n \\n•  The chatbot exhibits memory, possesses the ability to query internal DB  - by \\ngenerating SQL queries, search Wikipedia/Google News, formulate probing\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content='•  The chatbot exhibits memory, possesses the ability to query internal DB  - by \\ngenerating SQL queries, search Wikipedia/Google News, formulate probing \\nquestions to enhance analysis,  suggest better prompts  and can present output \\nin the form of charts, tables, or summarized text, detailing impacts. \\n \\n➢ Cell/CTB Forecast : Conducted mill -level production volume forecas t for \\nproduct - Cellulose and Containerboard to enhance inventory management, \\nproduction optimization, and customer satisfaction. \\n \\n•  Employed SARIMAX  on four years of monthly training data to forecast 12 \\nmonths ahead. Integrated planned outages and business forecast  as \\nexogenous variables in the models. \\n \\n➢  Sheet Feeders Pricing : Led a pricing strategy initiative to enhance and \\nstandardize pricing for Sheet Feeders products by leveraging historical \\ntransaction data to improve profitability. \\n \\n•  Proposed model focused on adjusting \"Ma terial Margin as % of Net Sales'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content='standardize pricing for Sheet Feeders products by leveraging historical \\ntransaction data to improve profitability. \\n \\n•  Proposed model focused on adjusting \"Ma terial Margin as % of Net Sales \\n(MMP)\" to enforce a 20% profitability floor by shifting low -margin transactions \\nbelow the MMP median. \\n \\n \\n \\n \\n \\n \\n     ADITYA  GAURAV  \\n \\uf028 +91-7845820047 \\n \\uf02a  advit200@gmail.com  \\n   Github.com/Advit200 \\n \\n   linkedin.com/in/advit200 \\n \\nExperienced Data Scientist with close to 9 years of \\nexpertise in  data analysis, ML/DL/Gen AI  and \\ntransforming business objectives into actionable data \\nscience tasks and generating value through AI. \\nDemonstrates strong analytical and problem -solving \\ncapabilities, meticulous attention to detail, and \\nexcellent teamwork skills. \\n \\nP R O F I L E  S Y N P O S I S \\n \\n▪ Adept at creating Enterprise grade Agentic LLM based \\napplication, fine tuning LLM/embedding model & RAG. \\n \\n▪ Proficient in developing , enhancing and maintaining'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content='▪ Adept at creating Enterprise grade Agentic LLM based \\napplication, fine tuning LLM/embedding model & RAG. \\n \\n▪ Proficient in developing , enhancing and maintaining \\nTime Series, Supervised Machine Learning and Deep \\nLearning based Predictive and Statistical models. \\n \\n \\n▪ Experienced in MLOps, managing the complete AI \\nlifecycle from ETL pipeline development to model \\ndeployment on cloud platforms – AWS and Azure. \\n \\n \\n▪ Possesses a solid grasp of Statistics, Hypothesis Testing \\nand Mathematics behind AI algorithms. \\n \\n \\n▪ Proficient in writing optimized Python code with a \\nstrong understanding of DSA and OOPs concepts. \\n \\n▪ Good knowledge of AWS and Azure cloud services, \\nincluding Azure ML Studio, Azure Data Factory, Azure \\nApp services and Azure Kubernetes Service. \\n \\n▪ Basic knowledge of Big Data ecosystem and Pyspark. \\n \\nT E C H N I C A L  S K I L L S \\nLanguages Python, SAS, SQL \\n \\nML Domain Regression, Classification, NLP, \\nClustering, Pricing, Time Series,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content='▪ Basic knowledge of Big Data ecosystem and Pyspark. \\n \\nT E C H N I C A L  S K I L L S \\nLanguages Python, SAS, SQL \\n \\nML Domain Regression, Classification, NLP, \\nClustering, Pricing, Time Series, \\nNetwork Analysis, Gen AI/LLM \\n \\nDatabases MySQL, MongoDB, Vector DB \\n \\n \\nWeb Framework Flask, Django, FastAPI \\n \\nBI Tool Power BI, Tableau \\n \\n \\nCloud AWS, Azure \\n \\nC E R T I F I C A T I O N \\n▪ Microsoft certified - Azure Fundamentals   \\n \\n \\n▪ Applied Accelerated AI – NPTEL (Nvidia) \\n \\n \\n▪ Data Structure & Algorithm,Python– NPTEL(IIT Madras) \\n \\n \\n▪ Network Analysis and Network Optimization – SAS \\n \\n▪ Generative AI with Large Language Model - Coursera \\n \\n \\nE D U C A T IO N \\nCollege Degree CGPA Year \\nBITS Pilani MTech-AIML \\n \\n8.49 2023-25 \\nVIT University, Vellore \\n \\nBTech-Mech \\n \\n8.55 2012-16 \\nDAV Public School \\n \\nClass-XII \\n \\n78% 2011 \\nDAV Public School Class-X 83% 2009'),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content=\"➢  BitterSweet: The project's objective was to construct an aggregator featuring integrated text analytics and insights for Koch Industries \\nby collecting and analysing reviews from diverse social media platforms . \\n \\n•  Conducted Sentiment Analysis, Aspect -based sentiment analysis  employing a NLI model and Topic Modelling  on the review text . The \\nresulting analysis provided valuable insights for organizational leaders to evaluate the company's reputation and identify potential issues \\nwithin their respective units. \\n \\n➢  Voice of customer : VOC project was aimed at identifying patterns in data and performing text analytics on customer’s feedback  to \\nfind key factors influencing customer experience during different stages of business and suggest possible areas of improvement. \\n \\n•  Employed diverse NLP techniques, including keyword extraction  (KeyBERT), NER (Spacy), Topic modelling  (BERTopic). Analysis of\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content=\"•  Employed diverse NLP techniques, including keyword extraction  (KeyBERT), NER (Spacy), Topic modelling  (BERTopic). Analysis of \\nnegative feedback revealed that delayed equipment delivery, fabrication issues, and response time were prominent factors cont ributing \\nto customer dissatisfaction. \\n \\n➢  Tissue Softness Prediction: Project's goal was to create a real-time alert system for operators, facilitating prompt quality checks and \\nminimizing waste due to tissue softness degradation. Developed a predictive model using streaming sensor data to predict tissue \\nsoftness at 10-minute intervals. \\n \\n•  Applied Genetic Algorithm for feature selection and built a unified XGBoost model across 10 plants . Deployed the model on SAS ESP . \\nUtilized SHAPLEY values for cause-effect analysis, aiding plant operators in decision-making. \\n \\nSr. Data Analyst | Accenture | Jan’ 17 – April’21\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content=\"Utilized SHAPLEY values for cause-effect analysis, aiding plant operators in decision-making. \\n \\nSr. Data Analyst | Accenture | Jan’ 17 – April’21 \\n \\n➢ OneReport : This project centers on the development of a web application for data owners to upload data files, with automatic data  \\nretrieval from the database, leading to the creation of a consolidated Data Lake that facilitates effortless Power BI refreshing. \\n \\n• Engineered the web application's backend using Django with MongoDB as the database, streamlining the data preprocessing pipel ine.  \\nImplemented features for data validation, checks, and PII or sensitive information encryption before database insertion. \\n \\n• Enabled Row-Level Security (RLS) and Scheduled Refresh for Power BI using Data Gateway. Additionally, developed a monthly email and   \\nTeams notification system through Flask API. \\n \\n➢  AQI Tool : The project's primary goal was to develop a tool for the comparative analysis of business documents (Excel, CSV, PDF, PPT)\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content=\"Teams notification system through Flask API. \\n \\n➢  AQI Tool : The project's primary goal was to develop a tool for the comparative analysis of business documents (Excel, CSV, PDF, PPT) \\nagainst a standardized template, based on 14 metrics, ultimately generating an Asset Quality Index (AQI) . \\n \\n• Designed a graphical user interface  (GUI) using tkinter, enabling users to select multiple files, apply filters/search functionality, and \\ngenerate detailed reports along with the AQI . Implemented OCR for extracting text from images and employed TF -IDF with cosine \\nsimilarity to identify duplicate images, sections, and tables within the documents . \\n \\n \\n                                                                                 \\n \\nPERSONAL PROJECTS \\n \\n• Developed a sentiment classification model, which involved training a custom BERT model with PyTorch. API deployment was managed \\nthrough Nginx, Docker, and Kubernetes on AWS-EKS.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-06-25T10:57:01+05:30', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_enabled': 'true', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_setdate': '2025-02-19T16:19:54Z', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_method': 'Standard', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_name': 'defa4170-0d19-0005-0004-bc88714345d2', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_siteid': '4bfc8473-b4f8-4a68-83c6-6b4fc5438261', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_actionid': '290907e1-96ba-4391-8e68-48c3808eb77c', 'msip_label_defa4170-0d19-0005-0004-bc88714345d2_contentbits': '0', 'author': 'Aditya Gaurav', 'moddate': '2025-06-25T10:57:01+05:30', 'source': '..\\\\data\\\\sample.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'sample.pdf', 'file_type': 'pdf'}, page_content='• Developed a sentiment classification model, which involved training a custom BERT model with PyTorch. API deployment was managed \\nthrough Nginx, Docker, and Kubernetes on AWS-EKS. \\n \\n• Constructed a supervised machine translation model utilizing the Locality -Sensitive Hashing (LSH)  based k-Nearest Neighbours (k-NN) \\ntechnique to translate English words into French. \\n \\n• Created a chess game between human-computer using the Minimax and Alpha-Beta Pruning algorithms for strategic move selection. \\n \\n• Developed a rabbit maze game employing A* and Hill climbing algorithm to navigate the maze efficiently and escape with minimal cost. \\n \\nACHIEVEMENTS \\n• Worked as Python & Data Analytics Instructor/Mentor for a batch of 10 freshers at KTC. \\n \\n• Received Spot Bonus 5 times in two years at KTC. \\n \\n \\n• Gold Badge in Python and SQL – HackerRank. \\n \\n• Secured GATE score (Mechanical) of 647 (95 percentile).')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b626b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U sentence-transformers\n",
    "# pip install chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129a3275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\66738\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f87364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model failed to load all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "class EmbedingManager():\n",
    "    def __init__(self, model_name: str = \"all-mpnet-base-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            self.model = SentenceTransformer(f\"sentence-transformers/{self.model_name}\")\n",
    "            print('model loaded successfully')\n",
    "        except Exception as e:\n",
    "            print(f'The model failed to load {self.model_name}')\n",
    "\n",
    "    def create_embedings(self, texts: List[str]) -> np.array:\n",
    "        if not self.model:\n",
    "            raise ('model is empty')\n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "    \n",
    "embeding_manager = EmbedingManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28dbe27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
